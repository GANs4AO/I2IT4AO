Image to Image Translation for Adaptive Optics - The Instructions!

Written by Jeffrey Smith

The team: Jeffrey Smith, Jesse Cranney, Charles Gretton and Daimen Gratadour
These papers: 

What is it
What does it do.

-----------------------------------------------------------
%%%PSF Reconstruction Experimentation from trained model%%%
-----------------------------------------------------------
(available in this project - see unpacking instructions in the checkpoints folder for 'Direct Amplitude' Network)

+ Creating the Roket Buffers (ie. building a statistical model for the AO system)
The roket buffers for the statistical estimation model are large, so I have not included them in the repo. I have a script for building them from a directory of config files - see the 'Roket_batch' script in the repo root folder.

+ Building a Long Exposure PSF from the pre-trained network
To create the inferred long exposure PSF the AO loop must be run and each inference is converted to a PSF and then averaged over the range of short exposure PSFs. Use the LEPSF_r0var_Div10 script as per the example below.

	Example LEPSF command:
python3 -i LEPSF_r0var_Div10.py --dataroot ~/GITs/wavefrontestimation_i2it/trainingdata/Sample_r012/ --load_size=512 --netG=unet_256 --input_nc=1 --output_nc=1 --dataset_mode pistonDivConst10 --name DirectAmplitude_test --model pix2pixExM --direction AtoB --num_test 20000 --ngf 64 --ndf 64 --epoch 65

+ Split code (drax update)
I have included the 'split code' as text files. Run these from the COMPASS '~shesha/guardians' folder in python. You will need to copy the 'drax.py' file over the one on the guardians folder as it has been augmented to add a second comparison. 

+ Circular Average and Long Exposure PSF view
use the script 'LEPSF_Paper_CirAvg' to generate the circuar average and top-down long exposer PSF chart from the paper. Modify paths and file names.

----------------------------------------------------------------------
%%%GAN Assisted Open Loop (GAOL) Experimentation from trained model%%%
----------------------------------------------------------------------

We do not use the Guardian tools from COMPASS for GAOL. The whole experimental workflow (once you have a trained network) can be done in the 'GAOL_Control' jupyter notebook. This is already configured for the pre trained network (you will need to unzip the network locally).

+ Adjust parameters to get results from paper.




--------------------------------
%%%Training your own networks%%%
--------------------------------

Training your own network requires some powerful GPUs so be prepared. GANs consume a lot of resources during training.

+ First step is to generate a large quantity of data. The Data_Generation folder in the project contains a COMPASS config file and a script to generate data used in the paper results we have published. Feel free to modify. We have subsequently used several atmospheric seeds to generate more diverse data, as well as adding other layers such as the DM screen to the training data set. (This significantly improves results - paper to come soon). 

+ Once you have your data, run the below command to train in the fasion of the pretrained model in the repo. There is a wide scope to change not only the AO loop parameters (COMPASS) but also the training paramters.

	Example cGAN training comand:
python I2IT_train.py --dataroot ./r0_093_W10_p512/ --load_size=512 --netG=unet_256 --input_nc=1 --output_nc=1 --dataset_mode pistonDivConst10 --name test_network --model pix2pixExM --direction AtoB --ngf 64 --ndf 64 --lambda_L1 150 --lambda_Ex 30

Training a GAN seems to be both art and science - mode collapse is easy to see as the Discriminator loss typically drops to zero. Preventing this requires good data knowledge, the right training parameters and arguably practice!



cGAN

UNET

